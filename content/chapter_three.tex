\section{Chapter 3: Measure of Performance and "Notions" of Optimality in Estimation Procedures}
	
	In general, there is a random variable of interest $X ~ P \in \mathbb{P} = \{P_\theta : \theta \in \Theta \}$. Now, we want to estimate $\theta$ in some reasonable manner with functions $\hat{\theta}$ based on the vector of observations, X. Our goal is to make this estimator somehow close to the true $\theta$. There are different things we can consider from, ease of computation, consistency, robustness, or minimizing expected risk, etc.

	In Chapter 2, we saw that plug-in estimates and method of moments are easy to compute. In Chapter 5, we will see that the MLE for canonical EF are consistent and we will also define consistency then.

	\subsection{Bayes Optimality}

		\textbf{Problem setup:}\\
		We are given a parametric model family $\mathbb{F} = \{P_\theta : \theta \in \Theta \}$, with an action space, A, and a loss function $l(\theta, a)$. 

		Then if we sample idd data $X ~ P_\theta$, and specify a decision procedure $\delta$ that can either be randomized, or not, then we define the risk function: $R(., \delta) : \Theta \rightarrow \mathbb{R}^+$

		$$R(\theta, \delta) = E_\theta [ l(\theta, \delta(X)) ]$$

		The risk is a measure of performance of your decision rule $\delta$ for this SPECIFIC model. At the very least, you do not want to consider inadmissable estimators (i.e. risk is worse for every value of $\theta$). In the Bayes context, we introduce a prior density $\pi$ for the parameter $\theta$. Then we can consider the following \textbf{Bayes risk}.

		$$r(\pi, \delta) = E[R(\theta, \delta)] = E[l(\theta, \delta(X))]$$

		\begin{definition}{Minimum Bayes Risk}
			$R(\pi) = inf \{ r(\pi, \delta) : \delta \in D \}$ is the minimum Bayes risk of the problem. 
		\end{definition}

		Our goal is to identify Bayes rules, $\delta_\pi^*$, such that: $r(\pi, \delta_\pi^*) = R(\pi)$.

		\subsubsection{Selection of Priors $\pi$}
			
			Improper priors

			Uniform/constant priorsÂ 

			Jeffrey's priors

			Conjugate priors

		\subsubsection{Bayes Estimation for Squared Error Loss}

			We are interested in estimating $q(\theta)$.

			In our setup, we now constrain our loss to be the quadratic loss function: $l(\theta, a) = (q(\theta) - a)^2$ using a nonrandomized decision rule, $\delta$. Consider $\pi(\theta)$ as our prior on the random vector $\theta$. We want now to find the function $\delta(X)$ that minimizes $r(\pi, \delta) = E[ q(\theta) - \delta(X) ]^2$.

			This boils down to either the Bayes risk being $\infty$ for all $\delta$, or that we arrive at the Bayes rule, $\delta^*(X) = E[ q(\theta) | X ]$, which is just the \textbf{mean of the posterior distribution!}

		\subsubsection{Bayes Estimation for General Loss Functions}

			We are interested in estimating $q(\theta)$.

			In our setup, we now consider general loss functions $l(\theta, a)$ using a nonrandomized decision rule, $\delta$. Consider $\pi(\theta)$ as our prior on the random vector $\theta$. We apply the same idea to formulate the posterior risk, which is:

			$$r(a | x) = E [ l(\theta, a) | X=x ]$$

			In BD proposition 3.2.1, though we know that if there exists an estimator, $\delta(x)$ that minimizes this function, then it is a Bayes rule, so we know that Bayes rule is indeed optimal in the decision theoretic framework for this specific risk functional.

	\subsection{Minimax Optimality}

		Minimax optimality is considering the "maximum", or supremum of possible risks over the space of parameter values. It is used in optimizing for the worst-case outcome, but in many cases are shown to be inadmissable!

	\subsection{Unbiased Optimality}

		So far, we have setup the rigorous framework of decision theory, and see that the function we are generally interested in optimizing is the risk. "Unbiasedness" sounds like an awesome property, but it simply implies that Bias is 0. However, in terms of risk, variance could be very big! Unbiased optimality is still important though because we can determine bounds on the variance through the \textbf{Information Inequality}, which will then allow us to check for the Uniform Minimum Variance Unbiased Estimate (UMVUE).

		Note that there are major issues with unbiased optimality:

		\begin{enumerate}
			\item existence: many times unbiased estimates do not exist
			\item Bayes estimates are biased: Bayes estimates are "optimal" in a sense, and they are biased... So bias can't be that bad.
			\item minimax estimates are also often biased
			\item not equivariant: unbiased estimators are not equivariant (i.e. not maintained under 1-1 transformations) as opposed to Maximum Likelihood Estimators
		\end{enumerate}

		There are also major pros though with unbiasedness!

		\begin{enumerate}
			\item In asymptotic theory, it would be nice generally to show unbiasedness because then, usually we can show variance going to 0, or a constant factor as n goes to $\infty$
		\end{enumerate}

		\subsubsection{Fisher Information (Matrix, or Value)}

			For rigor, BD states two regularity assumptions to  arrive at the lower bound for the variance of a statistic (i.e. the Information Inequality).

			\begin{enumerate}
				\item $\{x: p(x, \theta) > 0 \}$ is independent of $\theta$
				\item $\frac{\partial}{\partial \theta log(p(x, \theta))} < \infty$ and it exists
				\item If T is any statistic with $E_\theta[|T|] < \infty$ for all $\theta$, then the integration and differentiation of $\theta$ can be interchanged
			\end{enumerate}

			\begin{theorem}{Information Inequality:}
				T(X) is any statistic with a bounded variance, and $\psi(\theta)$ is the expected value of T.

				Then, we have: 
				$\psi(\theta)$ is differentiable and that $Var_\theta [ T(X) ] \ge \frac{[\psi'(\theta)]^2}{I(\theta)}$
			\end{theorem}

			When the estimator T is an unbiased estimate of $\theta$, then the numerator becomes 1, and so the variance of the estimator is solely bounded by this function, $I(\theta)$, which is known as the famed \textbf{Fisher Information (Matrix)}.

			\begin{definition}{Fisher Information:}
				$I(\theta) = E_\theta [ (\frac{\partial}{\partial \theta} log (p(X, \theta)))^2 ]$
			\end{definition}

	% \subsection{Robustness}

	% 	https://github.com/alyakin314/lqrt

	% 	\subsubsection{Gross Error Models}

	% 	\subsubsection{Sensitivity Curves}
